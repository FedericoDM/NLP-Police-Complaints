{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis for Police Summary Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Local imports\n",
    "from text_parser import TextParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:/Users/fdmol/Desktop/MSCAPP/CAPP30255/NLP-Police-Complaints/data/text_files\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions\n",
    "\n",
    "I define a class for reading and processing the data, I took some ideas from Matt's analysis to remove headers and other elements that are not relevant to us. This could also help in getting better results for the summarization task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below wraps HuggingFace's tokenizer and model to generate a summary for each complaint. As I mention below, I tweaked the parameters to get better summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(complaint_text, model_name):\n",
    "    \"\"\"\n",
    "    Generates a summary of a complaint given\n",
    "    the complaint text\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "    # Tokenize the text\n",
    "    inputs = tokenizer(\n",
    "        complaint_text, return_tensors=\"pt\", max_length=2512, truncation=True\n",
    "    )\n",
    "\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_length=1200,\n",
    "        min_length=40,\n",
    "        length_penalty=2.0,\n",
    "        no_repeat_ngram_size=2,\n",
    "        num_beams=4,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "\n",
    "    # Decode and print the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLP Task: Summarization\n",
    "\n",
    "I will use this model:\n",
    "\n",
    "https://huggingface.co/docs/transformers/main/en/model_doc/t5#transformers.T5ForConditionalGeneration\n",
    "\n",
    "In the cells below, I use the model to generate a summary for ten random complaints. The summaries are of medium quality, depending on each complaint. \n",
    "\n",
    "I did the following to try to improve the quality of the summaries:\n",
    "\n",
    "- Adjuster the `max_length` parameter to limit the length of the summary\n",
    "- Adjusted the `min_length` parameter to ensure the summary is at least a certain length\n",
    "- Adjusted the `num_beams` parameter to increase the number of beams used in beam search\n",
    "- Adjusted `no_repeat_ngram_size` parameter to avoid repeating n-grams in the summary\n",
    "\n",
    "I also experimented with the max_length of the tokens used in the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_falcon = \"Falconsai/text_summarization\"\n",
    "model_name_bart = \"facebook/bart-large-cnn\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Falconsai/text_summarization\n",
      "Complaint: 2018-1088298.txt\n",
      "=====================================\n",
      "Summary: alleged officer failed to activate his body worn camera during the arrest of in violation of rule s 1 and 2. ms. stated that while in the back of a police squadrol the accused used excessive force against in that he punched him in her face, choked him, and poked his eye as the officer yelling back “stop biting me and stop kicking me.”11 she rela ted that officer threatened to tase him if she didn’t comply, but said \n",
      "\n",
      "\n",
      "Model: Falconsai/text_summarization\n",
      "Complaint: 2018-1090124.txt\n",
      "=====================================\n",
      "Summary: june 28, 2018, at 7:55 a.m., at or near 4650 w. harrison street, chicago, il july 6, 2018 3:42. copa,4 accused field training officer carla jackson. she said she was waiting for the bus when she encountered his cousin, saying he had done nothing wrong. police arrived on scene and surrounded by multiple officers, including fto, said that they had their guns drawn and attempted to fight, shoot, and kill\n",
      "\n",
      "\n",
      "Model: Falconsai/text_summarization\n",
      "Complaint: 2018-1090310.txt\n",
      "=====================================\n",
      "Summary: officer kelly searched a citizen during which she improperly touched his sexual organs. cpd policy requires that, when possible, search ing should only be completed by members of the same gender of person being searched, copa finds - ii. recommended discipline for sustained allegations – if there is insufficient evidence to sustain, unfound or exonerate the allegations. 13 s04 (iv(b), investigatory stop system (effective july 10, 2017 to current). 14 g\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_parser = TextParser(PATH, nlp_task=\"summarization\")\n",
    "\n",
    "# Get a random list of 10 complaints\n",
    "complaints = os.listdir(PATH)\n",
    "complaints = [complaint for complaint in complaints if complaint.endswith(\".txt\")]\n",
    "complaints = random.sample(complaints, 3)\n",
    "\n",
    "\n",
    "for complaint in complaints:\n",
    "    complaint_text = text_parser.file_to_string(complaint)\n",
    "    print(f\"Model: {model_name_falcon}\")\n",
    "    summary = generate_summary(complaint_text, model_name_falcon)\n",
    "    print(f\"Complaint: {complaint}\")\n",
    "    print(\"=====================================\")\n",
    "    print(f\"Summary: {summary}\\n\\n\")\n",
    "\n",
    "    # print(f\"Model: {model_name_bart}\")\n",
    "    # summary = generate_summary(complaint_text, model_name_bart)\n",
    "    # print(f\"Summary: {summary}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some next steps could be:\n",
    "\n",
    "- Improve cleaning process to remove irrelevant headers and footers\n",
    "- Try other models\n",
    "- Finetune a model on this dataset (we would need to create a labeled dataset for this, and possibly generate the summaries by hand)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

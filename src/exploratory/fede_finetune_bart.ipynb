{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BART Finetuning\n",
    "\n",
    "By: Federico Dominguez Molina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fdmol\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fdmol\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\fdmol\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers datasets evaluate rouge_score\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "\n",
    "# Local imports\n",
    "from text_parser import TextParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"facebook/bart-large-cnn\"\n",
    "TEXT_FILES_PATH = (\n",
    "    \"C:/Users/fdmol/Desktop/MSCAPP/CAPP30255/NLP-Police-Complaints/data/text_files\"\n",
    ")\n",
    "DATA_PATH = \"C:/Users/fdmol/Desktop/MSCAPP/CAPP30255/NLP-Police-Complaints/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add local parameters\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and format training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing parsers for summarization\n"
     ]
    }
   ],
   "source": [
    "text_parser = TextParser(TEXT_FILES_PATH, nlp_task=\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-1060190.txt\n",
      "2016-1081599.txt\n",
      "2017-1087778.txt\n",
      "1085499.txt\n",
      "2010-1032871.txt\n",
      "2016-1081128.txt\n",
      "2018-1088501.txt\n",
      "1087317.txt\n",
      "2020-0001176.txt\n",
      "2016-1081113.txt\n",
      "1084293.txt\n",
      "2014-1072822.txt\n",
      "2017-1087234.txt\n",
      "2020-0002226.txt\n",
      "2014-1068262.txt\n",
      "1075325.txt\n",
      "1075770.txt\n",
      "2018-1089298.txt\n",
      "1080064.txt\n",
      "2019-1092229.txt\n",
      "1076615.txt\n",
      "2011-1047225.txt\n",
      "2013-1063129.txt\n",
      "1091501.txt\n",
      "2015-1078263.txt\n"
     ]
    }
   ],
   "source": [
    "training_data = pd.ExcelFile(DATA_PATH + \"/manual_summaries.xlsx\")\n",
    "training_data = training_data.parse(\"manual_summaries\")\n",
    "\n",
    "complete_texts = []\n",
    "processed_manual_summaries = []\n",
    "complaint_files = []\n",
    "\n",
    "# Get local\n",
    "for index, row in training_data.iterrows():\n",
    "    manual_summary = row[\"manual_summary\"]\n",
    "    complaint_file = row[\"complaint\"]\n",
    "\n",
    "    # Get complete, preprocessed text\n",
    "    complete_text = text_parser.file_to_string(f\"{TEXT_FILES_PATH}/{complaint_file}\")\n",
    "\n",
    "    # Preprocess manual summary\n",
    "    processed_manual_summary = text_parser.process_given_text(manual_summary)\n",
    "\n",
    "    complete_texts.append(complete_text)\n",
    "    processed_manual_summaries.append(processed_manual_summary)\n",
    "    complaint_files.append(complaint_file)\n",
    "\n",
    "\n",
    "training_set = pd.DataFrame(\n",
    "    {\n",
    "        \"complaint\": complaint_files,\n",
    "        \"complete_text\": complete_texts,\n",
    "        \"manual_summary\": processed_manual_summaries,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint</th>\n",
       "      <th>complete_text</th>\n",
       "      <th>manual_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-1060190.txt</td>\n",
       "      <td>/ u # 13 investigation number: / u #13 involv...</td>\n",
       "      <td>on february 16, 2013, chicago police officer \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-1081599.txt</td>\n",
       "      <td>summary report of investigation' time of inci...</td>\n",
       "      <td>on july 9, 2016, in alsip, illinois, officer e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-1087778.txt</td>\n",
       "      <td>date of incident: time of incident: location...</td>\n",
       "      <td>on december 10, 2017, officer rodney pickett a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1085499.txt</td>\n",
       "      <td>introductionon june 7th, 2017, chicago police...</td>\n",
       "      <td>on june 7, 2017, subject 1 was detained by chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-1032871.txt</td>\n",
       "      <td>/u # 10-1 investigation number: u # 10-1/  in...</td>\n",
       "      <td>on january 1, 2010, in chicago, officers a and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-1081128.txt</td>\n",
       "      <td>log #/ 1081128 1 summary report of investigati...</td>\n",
       "      <td>in june 2016, officer faced allegations of phy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-1088501.txt</td>\n",
       "      <td>=  1 p.m. oglesby avenue chicago, illinois 606...</td>\n",
       "      <td>on february 15, 2018, in chicago, police offic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1087317.txt</td>\n",
       "      <td>date of incident: time of incident: location...</td>\n",
       "      <td>on october 26, 2017, copa investigated an inci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-0001176.txt</td>\n",
       "      <td>civilian office of poli ce accountability   1 ...</td>\n",
       "      <td>the copa investigation into allegations agains...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-1081113.txt</td>\n",
       "      <td>summary report of investigation' date/time/lo...</td>\n",
       "      <td>on june 22, 2016, in chicago, officers , , and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1084293.txt</td>\n",
       "      <td>1  date of alleged incident: november 5, 2016...</td>\n",
       "      <td>subject 1 alleged a cpd officer injured him by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014-1072822.txt</td>\n",
       "      <td>page #1introduction:on 04 december 2014, at a...</td>\n",
       "      <td>on december 4, 2014, in chicago, officers a an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017-1087234.txt</td>\n",
       "      <td>summary report of investigation'  date of inc...</td>\n",
       "      <td>on august 12, 2017, officer a shot and injured...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-0002226.txt</td>\n",
       "      <td>civilian office of poli ce accountability   da...</td>\n",
       "      <td>on june 1, 2020, during a protest in chicago, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2014-1068262.txt</td>\n",
       "      <td>/u #14 investigation number: /u #14 involved ...</td>\n",
       "      <td>on march 28, 2014, off-duty chicago police off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1075325.txt</td>\n",
       "      <td>1 summary report of investigation1 p.m. locat...</td>\n",
       "      <td>the copa report details an incident from may 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1075770.txt</td>\n",
       "      <td>1the ipra investigator who worked on this case...</td>\n",
       "      <td>the report details an incident on june 20, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-1089298.txt</td>\n",
       "      <td>nan</td>\n",
       "      <td>the incident report covers an event where offi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1080064.txt</td>\n",
       "      <td>page 1 of 29 to: sharon r. fairley, chief admi...</td>\n",
       "      <td>on april 11, 2016, officers riordan and hitz p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-1092229.txt</td>\n",
       "      <td>1 p.m. location of incident: s. street p.m. o...</td>\n",
       "      <td>on january 4, 2019, off-duty officer david sod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1076615.txt</td>\n",
       "      <td>1 summary report of investigation1 a.m. – 3:0...</td>\n",
       "      <td>on august 10, 2015, a domestic disturbance occ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2011-1047225.txt</td>\n",
       "      <td>/ u #11 investigation number:  / u# 11 offic...</td>\n",
       "      <td>on july 25, 2011, officer a shot subject 1, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2013-1063129.txt</td>\n",
       "      <td>investigationnumber: involvedofficer #1: “offi...</td>\n",
       "      <td>the investigation into officer a's actions fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1091501.txt</td>\n",
       "      <td>civilian office of poli ce accountability  1 d...</td>\n",
       "      <td>the incident on october 22, 2018, involved off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2015-1078263.txt</td>\n",
       "      <td>civilian office of police accountabili ty  1 s...</td>\n",
       "      <td>the copa investigation into allegations made b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           complaint                                      complete_text  \\\n",
       "0   2013-1060190.txt   / u # 13 investigation number: / u #13 involv...   \n",
       "1   2016-1081599.txt   summary report of investigation' time of inci...   \n",
       "2   2017-1087778.txt    date of incident: time of incident: location...   \n",
       "3        1085499.txt   introductionon june 7th, 2017, chicago police...   \n",
       "4   2010-1032871.txt   /u # 10-1 investigation number: u # 10-1/  in...   \n",
       "5   2016-1081128.txt  log #/ 1081128 1 summary report of investigati...   \n",
       "6   2018-1088501.txt  =  1 p.m. oglesby avenue chicago, illinois 606...   \n",
       "7        1087317.txt    date of incident: time of incident: location...   \n",
       "8   2020-0001176.txt  civilian office of poli ce accountability   1 ...   \n",
       "9   2016-1081113.txt   summary report of investigation' date/time/lo...   \n",
       "10       1084293.txt   1  date of alleged incident: november 5, 2016...   \n",
       "11  2014-1072822.txt   page #1introduction:on 04 december 2014, at a...   \n",
       "12  2017-1087234.txt   summary report of investigation'  date of inc...   \n",
       "13  2020-0002226.txt  civilian office of poli ce accountability   da...   \n",
       "14  2014-1068262.txt   /u #14 investigation number: /u #14 involved ...   \n",
       "15       1075325.txt   1 summary report of investigation1 p.m. locat...   \n",
       "16       1075770.txt  1the ipra investigator who worked on this case...   \n",
       "17  2018-1089298.txt                                                nan   \n",
       "18       1080064.txt  page 1 of 29 to: sharon r. fairley, chief admi...   \n",
       "19  2019-1092229.txt   1 p.m. location of incident: s. street p.m. o...   \n",
       "20       1076615.txt   1 summary report of investigation1 a.m. – 3:0...   \n",
       "21  2011-1047225.txt    / u #11 investigation number:  / u# 11 offic...   \n",
       "22  2013-1063129.txt  investigationnumber: involvedofficer #1: “offi...   \n",
       "23       1091501.txt  civilian office of poli ce accountability  1 d...   \n",
       "24  2015-1078263.txt  civilian office of police accountabili ty  1 s...   \n",
       "\n",
       "                                       manual_summary  \n",
       "0   on february 16, 2013, chicago police officer \"...  \n",
       "1   on july 9, 2016, in alsip, illinois, officer e...  \n",
       "2   on december 10, 2017, officer rodney pickett a...  \n",
       "3   on june 7, 2017, subject 1 was detained by chi...  \n",
       "4   on january 1, 2010, in chicago, officers a and...  \n",
       "5   in june 2016, officer faced allegations of phy...  \n",
       "6   on february 15, 2018, in chicago, police offic...  \n",
       "7   on october 26, 2017, copa investigated an inci...  \n",
       "8   the copa investigation into allegations agains...  \n",
       "9   on june 22, 2016, in chicago, officers , , and...  \n",
       "10  subject 1 alleged a cpd officer injured him by...  \n",
       "11  on december 4, 2014, in chicago, officers a an...  \n",
       "12  on august 12, 2017, officer a shot and injured...  \n",
       "13  on june 1, 2020, during a protest in chicago, ...  \n",
       "14  on march 28, 2014, off-duty chicago police off...  \n",
       "15  the copa report details an incident from may 2...  \n",
       "16  the report details an incident on june 20, 201...  \n",
       "17  the incident report covers an event where offi...  \n",
       "18  on april 11, 2016, officers riordan and hitz p...  \n",
       "19  on january 4, 2019, off-duty officer david sod...  \n",
       "20  on august 10, 2015, a domestic disturbance occ...  \n",
       "21  on july 25, 2011, officer a shot subject 1, wh...  \n",
       "22  the investigation into officer a's actions fou...  \n",
       "23  the incident on october 22, 2018, involved off...  \n",
       "24  the copa investigation into allegations made b...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to finetune BART using the `transformers` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "\n",
    "    prediction_lens = [\n",
    "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions\n",
    "    ]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mSeq2SeqTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy_awesome_billsum_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_total_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredict_with_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpush_to_hub\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[0;32m     16\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     17\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     25\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32m<string>:119\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, sharded_ddp, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, include_inputs_for_metrics, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, sortish_sampler, predict_with_generate, generation_max_length, generation_num_beams, generation_config)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\training_args.py:1405\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1399\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(version\u001b[38;5;241m.\u001b[39mparse(torch\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mbase_version) \u001b[38;5;241m==\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16:\n\u001b[0;32m   1400\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--optim adamw_torch_fused with --fp16 requires PyTorch>2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[1;32m-> 1405\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1406\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1407\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (get_xla_device_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1408\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16_full_eval)\n\u001b[0;32m   1409\u001b[0m ):\n\u001b[0;32m   1410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1412\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (`--fp16_full_eval`) can only be used on CUDA or NPU devices.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1413\u001b[0m     )\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1416\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1417\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1422\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16_full_eval)\n\u001b[0;32m   1423\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\training_args.py:1852\u001b[0m, in \u001b[0;36mTrainingArguments.device\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;124;03mThe device used by this process.\u001b[39;00m\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1851\u001b[0m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m-> 1852\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_devices\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\utils\\generic.py:54\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, obj, objtype)\u001b[0m\n\u001b[0;32m     52\u001b[0m cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, attr, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(obj, attr, cached)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cached\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\training_args.py:1767\u001b[0m, in \u001b[0;36mTrainingArguments._setup_devices\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[0;32m   1766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available(min_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.20.1\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m   1768\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1769\u001b[0m         )\n\u001b[0;32m   1770\u001b[0m     AcceleratorState\u001b[38;5;241m.\u001b[39m_reset_state(reset_partial_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1771\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`"
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"my_awesome_billsum_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "# trainer = Seq2SeqTrainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_billsum[\"train\"],\n",
    "#     eval_dataset=tokenized_billsum[\"test\"],\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator,\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )\n",
    "\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
